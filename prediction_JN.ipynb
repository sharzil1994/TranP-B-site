{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cadf33d-0437-4cae-80fc-9534357f69f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 10:53:26.203450: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-29 10:53:26.246765: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-29 10:53:26.246804: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-29 10:53:26.246832: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-29 10:53:26.255356: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-29 10:53:28.642609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9631 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:8b:00.0, compute capability: 7.5\n",
      "2024-03-29 10:53:52.572279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-03-29 10:53:53.593531: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-29 10:53:53.734563: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 9ms/step\n",
      "DVSGTVCLSALPPEATDTLNLIASDGPFPYSQDGVVFQNRESVLPTQSYGYYHEYTVITPGARTRGTRRIITGEATQEDYYTGDHYATFSLIDQTC\n",
      "000000000000010000000000100111111010011110010011100000110110001110111000000100000000011100000000\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Aug  7 01:33:14 2023\n",
    "\n",
    "@author: sharzil\n",
    "\"\"\"\n",
    "import argparse\n",
    "import  pickle\n",
    "import numpy as np\n",
    "import random \n",
    "import sys,os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, MaxPooling1D,LayerNormalization, Dropout, Flatten, Dense, concatenate ,AveragePooling1D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import confusion_matrix, recall_score, roc_curve, roc_auc_score, auc\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import losses\n",
    "from sklearn.utils import compute_class_weight\n",
    "import random\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "np.random.seed(seed=21)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from transformers import T5EncoderModel, T5Tokenizer\n",
    "# import torch\n",
    "import h5py\n",
    "import time\n",
    "\n",
    "def windowing(features,w_size):   \n",
    "    to=0\n",
    "    for index in features:\n",
    "        b=np.shape(index)[0]\n",
    "        to=to+b\n",
    "    \n",
    "        \n",
    "    \n",
    "    a=features[0]\n",
    "    fea_len=np.shape(a)[1]\n",
    "    finalout1=np.zeros([to,w_size,fea_len],'float')\n",
    "    \n",
    "    l=0\n",
    "    for i in range(0,len(features)):\n",
    "        temp_features=features[i]\n",
    "        \n",
    "        for j in range( 0, np.shape(temp_features)[0]):\n",
    "            \n",
    "            \n",
    "            for k in range(0,w_size):\n",
    "                \n",
    "                k1=int(j+k-((w_size-1)/2))\n",
    "                \n",
    "                if k1<0 or k1 > np.shape(temp_features)[0]-1:\n",
    "                    pass\n",
    "                else:\n",
    "                    finalout1[l,k,:]=temp_features[k1,:]\n",
    "            l=l+1\n",
    "    finalout1=finalout1.reshape((finalout1.shape[0], finalout1.shape[1],finalout1.shape[2], 1))\n",
    "    return finalout1\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def label( labels):   \n",
    "    final_label=labels\n",
    "    \n",
    "    to=0\n",
    "    for i in range(0,len(final_label)):\n",
    "        temp_label=final_label[i]\n",
    "        for j in range(0,len(temp_label)):\n",
    "            to=to+1\n",
    "    \n",
    "    \n",
    "    finallabel=np.zeros([to],'int')\n",
    "    \n",
    "    l=0\n",
    "    for i in range(0,len(final_label)):\n",
    "        # print(i)\n",
    "\n",
    "        temp_label=final_label[i]\n",
    "        \n",
    "        for j in range( 0, len(temp_label)):\n",
    "            \n",
    "\n",
    "            finallabel[l]=temp_label[j]\n",
    "            l=l+1\n",
    "            \n",
    "    return  finallabel \n",
    "\n",
    "def Protein_seq_feature(seqs1,seqs4):\n",
    "    \n",
    "    for index in seqs1.keys():\n",
    "        a=seqs1[index]\n",
    "        b=np.shape(a)[0]\n",
    "        c=seqs4[index]\n",
    "        c=c.reshape((1,len(c)))\n",
    "        d=seqs4[index]\n",
    "        d=d.reshape((1,len(d)))\n",
    "        for index_1 in range(b-1):\n",
    "            d=np.concatenate((d,c),axis=0)\n",
    "        seqs4[index]=d\n",
    "    return seqs4\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def predict(prot_test_r,prot_test_p_OHE):\n",
    "    gpu=6\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu)\n",
    "\n",
    "    new_model = tf.keras.models.load_model(f\"my_model_new.keras\")\n",
    "\n",
    "    pred_y = new_model.predict([prot_test_r,prot_test_p_OHE])\n",
    "    for i in range(len(pred_y)):\n",
    "        if pred_y[i] < 0.5:\n",
    "            pred_y[i] = 0;\n",
    "        else:\n",
    "            pred_y[i] = 1;\n",
    "    pred_y=np.squeeze(pred_y)        \n",
    "    pred_y=pred_y.astype('int')\n",
    "\n",
    "    return(pred_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def embedding(input_seq):\n",
    "\n",
    "    \n",
    "    seq_path = \"./protT5/example_seqs.fasta\"\n",
    "    \n",
    "\n",
    "    per_residue = True \n",
    "    per_residue_path = \"./protT5/output/per_residue_embeddings.h5\" # where to store the embeddings\n",
    "\n",
    "    per_protein = True\n",
    "    per_protein_path = \"./protT5/output/per_protein_embeddings.h5\" # where to store the embeddings\n",
    "\n",
    "    sec_struct = False\n",
    "    sec_struct_path = \"./protT5/output/ss3_preds.fasta\" # file for storing predictions\n",
    "    \n",
    "    assert per_protein is True or per_residue is True or sec_struct is True, print(\n",
    "        \"Minimally, you need to active per_residue, per_protein or sec_struct. (or any combination)\")\n",
    "    \n",
    "    \n",
    "    #@title Import dependencies and check whether GPU is available. { display-mode: \"form\" }\n",
    "\n",
    "    # device = torch.device('cuda:6' if torch.cuda.is_available() else 'cpu')\n",
    "    # print(\"Using {}\".format(device))\n",
    "    \n",
    "    device = torch.device('cpu')\n",
    "    def find_alphabet(string, alphabet):\n",
    "      return alphabet in string\n",
    "    def one_hot_encode(sequence):\n",
    "    # Define dictionary mapping amino acids to their indices\n",
    "      amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "      aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "    \n",
    "      # Initialize one-hot encoded sequence\n",
    "      one_hot_sequence = []\n",
    "      \n",
    "      # Iterate over each amino acid in the sequence\n",
    "      for aa in sequence:\n",
    "          # Initialize one-hot encoding vector for current amino acid\n",
    "          encoding = [0] * len(amino_acids)\n",
    "          # Set the index corresponding to the amino acid to 1\n",
    "          if find_alphabet(amino_acids, aa):\n",
    "              encoding[aa_to_index[aa]] = 1\n",
    "          # Append the one-hot encoding vector to the sequence\n",
    "          one_hot_sequence.append(encoding)\n",
    "      one_hot_sequence = np.array(one_hot_sequence)   \n",
    "      return one_hot_sequence\n",
    "    \n",
    "    def get_T5_model():\n",
    "        model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\")\n",
    "        model = model.to(device) # move model to GPU\n",
    "        model = model.eval() # set model to evaluation model\n",
    "        tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
    "    \n",
    "        return model, tokenizer\n",
    "\n",
    "    \n",
    "    def get_embeddings( model, tokenizer, seqs, per_residue, per_protein, sec_struct, \n",
    "                       max_residues=4000, max_seq_len=1000, max_batch=100 ):\n",
    "    \n",
    "        if sec_struct:\n",
    "          sec_struct_model = load_sec_struct_model()\n",
    "    \n",
    "        results = {\"residue_embs\" : dict(), \n",
    "                   \"protein_embs\" : dict(),\n",
    "                   \"sec_structs\" : dict() \n",
    "                   }\n",
    "    \n",
    "        # sort sequences according to length (reduces unnecessary padding --> speeds up embedding)\n",
    "        seq_dict   = sorted( seqs.items(), key=lambda kv: len( seqs[kv[0]] ), reverse=True )\n",
    "        start = time.time()\n",
    "        batch = list()\n",
    "        for seq_idx, (pdb_id, seq) in enumerate(seq_dict,1):\n",
    "            seq = seq\n",
    "            seq_len = len(seq)\n",
    "            seq = ' '.join(list(seq))\n",
    "            batch.append((pdb_id,seq,seq_len))\n",
    "    \n",
    "            # count residues in current batch and add the last sequence length to\n",
    "            # avoid that batches with (n_res_batch > max_residues) get processed \n",
    "            n_res_batch = sum([ s_len for  _, _, s_len in batch ]) + seq_len \n",
    "            if len(batch) >= max_batch or n_res_batch>=max_residues or seq_idx==len(seq_dict) or seq_len>max_seq_len:\n",
    "                pdb_ids, seqs, seq_lens = zip(*batch)\n",
    "                batch = list()\n",
    "    \n",
    "                # add_special_tokens adds extra token at the end of each sequence\n",
    "                token_encoding = tokenizer.batch_encode_plus(seqs, add_special_tokens=True, padding=\"longest\")\n",
    "                input_ids      = torch.tensor(token_encoding['input_ids']).to(device)\n",
    "                attention_mask = torch.tensor(token_encoding['attention_mask']).to(device)\n",
    "                embedding_repr = model(input_ids, attention_mask=attention_mask)\n",
    "                #try:\n",
    "                #    with torch.no_grad():\n",
    "                        # returns: ( batch-size x max_seq_len_in_minibatch x embedding_dim )\n",
    "                #        embedding_repr = model(input_ids, attention_mask=attention_mask)\n",
    "                #except RuntimeError:\n",
    "                #    print(\"RuntimeError during embedding for {} (L={})\".format(pdb_id, seq_len))\n",
    "                #    continue\n",
    "    \n",
    "                for batch_idx, identifier in enumerate(pdb_ids): # for each protein in the current mini-batch\n",
    "                    s_len = seq_lens[batch_idx]\n",
    "                    # slice off padding --> batch-size x seq_len x embedding_dim  \n",
    "                    emb = embedding_repr.last_hidden_state[batch_idx,:s_len]\n",
    "                    if per_residue: # store per-residue embeddings (Lx1024)\n",
    "                        results[\"residue_embs\"][ identifier ] = emb.detach().cpu().numpy().squeeze()\n",
    "    \n",
    "    \n",
    "        passed_time=time.time()-start\n",
    "        print(passed_time)\n",
    "        print(len(results[\"residue_embs\"]))\n",
    "        return results\n",
    "    \n",
    "    model, tokenizer = get_T5_model()\n",
    "    # test=dict()\n",
    "    input_seqence=dict()\n",
    "    # test['test']='DVSGTVCLSALPPEATDTLNLIASDGPFPYSQDGVVFQNRESVLPTQSYGYYHEYTVITPGARTRGTRRIITGEATQEDYYTGDHYATFSLIDQTC'\n",
    "    # test['test']='AQVQLVESGGGLVQAGGSLRLSCAVSGRPFSEYNLGWFRQAPGKEREFVARIRSSGTTVYTDSVKGRFSASRDNAKNMGYLQLNSLEPEDTAVYYCAMSRVDTDSPAFYDYWGQGTQVTVSTPR'\n",
    "    input_seqence['input_seq']=input_seq\n",
    "    # print(len(test['test']))\n",
    "    per_residue = True \n",
    "    results=get_embeddings( model, tokenizer, input_seqence,\n",
    "                         per_residue, per_protein, sec_struct)\n",
    "    \n",
    "    ppi_embd=dict()\n",
    "\n",
    "    for index1 in results['residue_embs'].keys():\n",
    "        ppi_embd[index1]=results['residue_embs'][index1]\n",
    "        \n",
    "    protein_onehot=dict()\n",
    "\n",
    "    for index in input_seqence.keys():\n",
    "        temp=input_seqence[index]\n",
    "        encoded_sequence = one_hot_encode(temp)\n",
    "        protein_onehot[index]=encoded_sequence\n",
    "\n",
    "    win_size=5\n",
    "    \n",
    "    prot_test_3d=dict()\n",
    "    for index in ppi_embd.keys():\n",
    "        prot_test_3d[index]=ppi_embd[index]       \n",
    "    prot_test_3=np.array(list(prot_test_3d.items()),dtype=object)[:,1]\n",
    "    prot_test_3=windowing(prot_test_3,win_size)\n",
    "\n",
    "    prot_test_OHE=dict()\n",
    "    for index in protein_onehot.keys():\n",
    "        prot_test_OHE[index]=protein_onehot[index]       \n",
    "    prot_test_OHE=np.array(list(prot_test_OHE.items()),dtype=object)[:,1]\n",
    "    prot_test_OHE=windowing(prot_test_OHE,win_size)\n",
    "    \n",
    "    return prot_test_3,prot_test_OHE\n",
    "  \n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-s\", \"--protein_sequence\", type = str, help = \"PDBID (e.g. EDRLKIDVIDWLVFDPAQRAE)\")\n",
    "    args = parser.parse_args()    \n",
    "    if args.protein_sequence == None or len(args.protein_sequence) <= 10:\n",
    "        print(\"Invalid protein sequence!\")\n",
    "    else:\n",
    "\n",
    "        input_seq=args.protein_sequence\n",
    "        [f1,f2]=embedding(input_seq)\n",
    "        pred=predict(f1,f2)\n",
    "        pred2=''\n",
    "        for index in pred:\n",
    "            pred2=pred2+str(index)\n",
    "        print(input_seq)\n",
    "        print(pred2)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-s\", \"--protein_sequence\", type = str, help = \"PDBID (e.g. EDRLKIDVIDWLVFDPAQRAE)\")\n",
    "    args = parser.parse_args()    \n",
    "    if args.protein_sequence == None or len(args.protein_sequence) <= 10:\n",
    "        print(\"Invalid protein sequence!\")\n",
    "    else:\n",
    "\n",
    "        input_seq=args.protein_sequence\n",
    "        [f1,f2]=embedding(input_seq)\n",
    "        pred=predict(f1,f2)\n",
    "        pred2=''\n",
    "        for index in pred:\n",
    "            pred2=pred2+str(index)\n",
    "        print(input_seq)\n",
    "        print(pred2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
